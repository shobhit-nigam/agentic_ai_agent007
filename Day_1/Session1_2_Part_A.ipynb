{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f53cd766",
   "metadata": {},
   "source": [
    "\n",
    "# Session 1 and 2 (Part A) — Agentic AI: Labs \n",
    "\n",
    "This notebook contains **reference implementations** for Session 1:\n",
    "- Lab 1: Reactive Chatbot (baseline)\n",
    "- Lab 2: Tool-Using Agent\n",
    "- Lab 3: Planning Agent\n",
    "- Lab 4: Memory Demo\n",
    "- Lab 5: Feedback & Retry\n",
    "\n",
    "> ⚠️ **Note**: Internet access may be disabled. All examples include **mocked** functions for smooth execution, plus commented code showing how to switch to real APIs later.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15e659f",
   "metadata": {},
   "source": [
    "\n",
    "## Setup\n",
    "\n",
    "We define a tiny **mock LLM** and **mock tools** so everything runs offline.\n",
    "If you want to use real APIs later:\n",
    "- Replace `mock_chat()` with an OpenAI/Anthropic client call.\n",
    "- Replace `mock_get_weather()` with a real HTTP request (e.g., `wttr.in` or a weather API).\n",
    "- Replace `mock_search_wikipedia()` with a real Wikipedia client.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d270f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Setup complete (mock LLM & tools ready).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any\n",
    "import random\n",
    "import time\n",
    "\n",
    "# ------------------ Mock LLM ------------------\n",
    "def mock_chat(messages: List[Dict[str, str]], model: str = \"mock-gpt\") -> str:\n",
    "    \"\"\"A very small mock that returns deterministic but helpful text.\"\"\"\n",
    "    last_user = next((m[\"content\"] for m in reversed(messages) if m[\"role\"] == \"user\"), \"\")\n",
    "    if \"break down\" in last_user.lower() or \"steps\" in last_user.lower():\n",
    "        return (\"1) Clarify requirements\\n2) Plan tasks\\n3) Execute tools\\n\"\n",
    "                \"4) Verify outcomes\\n5) Summarize & next steps\")\n",
    "    if \"capital of france\" in last_user.lower():\n",
    "        return \"Paris.\"\n",
    "    if \"dinner\" in last_user.lower():\n",
    "        return \"Consider a casual bistro in River North and a lakefront walk afterwards.\"\n",
    "    return f\"(mocked) Response to: {last_user[:80]}...\"\n",
    "\n",
    "# ------------------ Mock Tools ------------------\n",
    "def mock_get_weather(city: str) -> str:\n",
    "    temperatures = {\"chicago\": \"+22°C 🌤️\", \"new york\": \"+24°C 🌥️\", \"london\": \"+17°C 🌧️\"}\n",
    "    return f\"{city.title()}: {temperatures.get(city.lower(), '+20°C ☁️ (mock)')}\"\n",
    "\n",
    "def mock_search_wikipedia(query: str) -> str:\n",
    "    return f\"(mock) Top summary for '{query}': This is a concise encyclopedia-style overview.\"\n",
    "\n",
    "# Retry helper\n",
    "def with_retry(fn, retries=3, delay=0.5):\n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            return fn()\n",
    "        except Exception as e:\n",
    "            if i == retries - 1:\n",
    "                raise\n",
    "            time.sleep(delay)\n",
    "\n",
    "print(\"✅ Setup complete (mock LLM & tools ready).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfbe47d",
   "metadata": {},
   "source": [
    "\n",
    "## Lab 1 — Reactive Chatbot (Baseline)\n",
    "\n",
    "A minimal, **reactive** chatbot. No tools. No memory. No autonomy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d68dca43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What is the capital of France?\n",
      "A: Paris.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def chatbot(question: str) -> str:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": question},\n",
    "    ]\n",
    "    return mock_chat(messages)\n",
    "\n",
    "print(\"Q: What is the capital of France?\")\n",
    "print(\"A:\", chatbot(\"What is the capital of France?\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e9d9d7",
   "metadata": {},
   "source": [
    "\n",
    "## Lab 2 — Tool-Using Agent\n",
    "\n",
    "A tiny **agent** that decides whether to call a **weather tool** or fallback to the LLM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93e4d713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: I decided to call the weather tool.\n",
      "Weather result → Chicago: +22°C 🌤️\n",
      "Agent: No tool needed; using LLM.\n",
      "Consider a casual bistro in River North and a lakefront walk afterwards.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def tool_using_agent(user_input: str) -> str:\n",
    "    text = user_input.lower()\n",
    "    if \"weather\" in text:\n",
    "        # naive city extraction\n",
    "        city = \"Chicago\"\n",
    "        for name in [\"Chicago\", \"New York\", \"London\"]:\n",
    "            if name.lower() in text:\n",
    "                city = name\n",
    "                break\n",
    "        print(\"Agent: I decided to call the weather tool.\")\n",
    "        weather = mock_get_weather(city)\n",
    "        return f\"Weather result → {weather}\"\n",
    "    else:\n",
    "        print(\"Agent: No tool needed; using LLM.\")\n",
    "        return mock_chat([{\"role\": \"user\", \"content\": user_input}])\n",
    "\n",
    "print(tool_using_agent(\"What's the weather in Chicago today?\"))\n",
    "print(tool_using_agent(\"Suggest an evening dinner plan.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "239d3cb3-594f-40d0-ba3b-96845fc6beec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I checked the weather tool: London: ⛅️  +54°F\n",
      "\n",
      "Agent: No tool needed; using LLM.\n",
      "Consider a casual bistro in River North and a lakefront walk afterwards.\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "from openai import OpenAI\n",
    "\n",
    "#client = OpenAI()\n",
    "\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    url = f\"http://wttr.in/{city}?format=3\"\n",
    "    r = requests.get(url, timeout=8)\n",
    "    r.raise_for_status()\n",
    "    return r.text \n",
    "\n",
    "\n",
    "def tool_using_agent(user_input: str) -> str:\n",
    "    text = user_input.lower()\n",
    "    if \"weather\" in text:\n",
    "        # naive city extraction\n",
    "        city = \"Chicago\"\n",
    "        for name in [\"Chicago\", \"New York\", \"London\"]:\n",
    "            if name.lower() in text:\n",
    "                city = name\n",
    "                break\n",
    "        try:\n",
    "            weather = get_weather(city)\n",
    "            return f\"I checked the weather tool: {weather}\"\n",
    "        except Exception as e:\n",
    "            return f\"Sorry weather tool failed: {e}\"\n",
    "    else:\n",
    "        print(\"Agent: No tool needed; using LLM.\")\n",
    "        return mock_chat([{\"role\": \"user\", \"content\": user_input}])\n",
    "\n",
    "print(tool_using_agent(\"What's the weather in London today?\"))\n",
    "print(tool_using_agent(\"Suggest an evening dinner plan.\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574c3c96",
   "metadata": {},
   "source": [
    "\n",
    "## Lab 3 — Planning Agent\n",
    "\n",
    "Ask the LLM to **break down a goal** into steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "101fb9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Clarify requirements\n",
      "2) Plan tasks\n",
      "3) Execute tools\n",
      "4) Verify outcomes\n",
      "5) Summarize & next steps\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def planning_agent(goal: str) -> str:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a planning agent.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Break down the steps to: {goal}\"},\n",
    "    ]\n",
    "    return mock_chat(messages)\n",
    "\n",
    "print(planning_agent(\"Organize a team offsite event\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28fb83d",
   "metadata": {},
   "source": [
    "\n",
    "## Lab 4 — Memory Demo\n",
    "\n",
    "Keep simple **short-term memory** across calls.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2259a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received: Book flight to New York | Memory: ['Book flight to New York']\n",
      "Received: Change it to tomorrow | Memory: ['Book flight to New York', 'Change it to tomorrow']\n",
      "Received: Add one extra bag | Memory: ['Book flight to New York', 'Change it to tomorrow', 'Add one extra bag']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "conversation_memory = []\n",
    "\n",
    "def memory_agent(user_input: str) -> str:\n",
    "    conversation_memory.append(user_input)\n",
    "    return f\"Received: {user_input} | Memory: {conversation_memory[-3:]}\"\n",
    "\n",
    "print(memory_agent(\"Book flight to New York\"))\n",
    "print(memory_agent(\"Change it to tomorrow\"))\n",
    "print(memory_agent(\"Add one extra bag\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e9dcb1d-2451-4ec0-8f8f-9f096569f439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Book flight to New York', 'Change it to tomorrow', 'Add one extra bag']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6f07b3",
   "metadata": {},
   "source": [
    "\n",
    "## Lab 5 — Feedback & Retry\n",
    "\n",
    "Retry an action that may fail. Here we **simulate** failure with randomness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "adbb7f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action succeeded ✅ (attempt 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def flaky_action():\n",
    "    if random.random() < 0.6:\n",
    "        raise RuntimeError(\"Transient tool error.\")\n",
    "    return \"Action succeeded ✅\"\n",
    "\n",
    "def feedback_agent():\n",
    "    attempts = 0\n",
    "    max_attempts = 3\n",
    "    while attempts < max_attempts:\n",
    "        try:\n",
    "            result = flaky_action()\n",
    "            return f\"{result} (attempt {attempts+1})\"\n",
    "        except Exception as e:\n",
    "            attempts += 1\n",
    "            print(f\"Attempt {attempts} failed: {e}. Retrying...\")\n",
    "    return \"Failed after 3 attempts. Please try again later.\"\n",
    "\n",
    "print(feedback_agent())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f4e156db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather: Chicago: +22°C 🌤️\n",
      "Plan: Consider a casual bistro in River North and a lakefront walk afterwards.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def trip_planner(city: str = \"Chicago\"):\n",
    "    weather = mock_get_weather(city)\n",
    "    plan = mock_chat([\n",
    "        {\"role\": \"system\", \"content\": \"You are a trip planning agent.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"The weather is: {weather}. Suggest an evening dinner plan.\"}\n",
    "    ])\n",
    "    return f\"Weather: {weather}\\nPlan: {plan}\"\n",
    "\n",
    "print(trip_planner(\"Chicago\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ac4a519",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'select_tool_and_answer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m prefix \u001b[38;5;241m+\u001b[39m select_tool_and_answer(query)\n\u001b[1;32m     16\u001b[0m agent \u001b[38;5;241m=\u001b[39m ToolAgentWithMemory()\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28mprint\u001b[39m(agent\u001b[38;5;241m.\u001b[39mhandle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms the weather in Chicago?\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(agent\u001b[38;5;241m.\u001b[39mhandle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSearch Wikipedia about Large Language Models\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(agent\u001b[38;5;241m.\u001b[39mhandle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecommend a dinner plan\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "Cell \u001b[0;32mIn[28], line 14\u001b[0m, in \u001b[0;36mToolAgentWithMemory.handle\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mremember(query)\n\u001b[1;32m     13\u001b[0m prefix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(memory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prefix \u001b[38;5;241m+\u001b[39m select_tool_and_answer(query)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'select_tool_and_answer' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "class ToolAgentWithMemory:\n",
    "    def __init__(self, memory_size: int = 3):\n",
    "        self.memory = []\n",
    "        self.memory_size = memory_size\n",
    "\n",
    "    def remember(self, q: str):\n",
    "        self.memory.append(q)\n",
    "        if len(self.memory) > self.memory_size:\n",
    "            self.memory.pop(0)\n",
    "\n",
    "    def handle(self, query: str) -> str:\n",
    "        self.remember(query)\n",
    "        prefix = f\"(memory: {self.memory})\\n\"\n",
    "        return prefix + select_tool_and_answer(query)\n",
    "\n",
    "agent = ToolAgentWithMemory()\n",
    "print(agent.handle(\"What's the weather in Chicago?\"))\n",
    "print(agent.handle(\"Search Wikipedia about Large Language Models\"))\n",
    "print(agent.handle(\"Recommend a dinner plan\"))\n",
    "print(agent.handle(\"What's the weather in New York?\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb94553d",
   "metadata": {},
   "source": [
    "\n",
    "## Take-Home Assignment 2 — Mini Planner Agent (Execute One Step)\n",
    "\n",
    "- Break down a goal into steps.\n",
    "- **Execute one step** (e.g., fetch weather).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfae1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def execute_step(step: str) -> str:\n",
    "    step_l = step.lower()\n",
    "    if \"weather\" in step_l:\n",
    "        return mock_get_weather(\"Chicago\")\n",
    "    return f\"(mock) Executed step: {step}\"\n",
    "\n",
    "def mini_planner_with_execution(goal: str):\n",
    "    steps_text = planning_agent(goal)\n",
    "    steps = [s.strip() for s in steps_text.split(\"\\n\") if s.strip()]\n",
    "    report = []\n",
    "    for i, step in enumerate(steps, 1):\n",
    "        result = execute_step(step)\n",
    "        report.append(f\"Step {i}: {step} -> {result}\")\n",
    "    return \"\\n\".join(report)\n",
    "\n",
    "print(mini_planner_with_execution(\"Plan a day in Chicago\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ebfaa8",
   "metadata": {},
   "source": [
    "\n",
    "## Take-Home Assignment 3 — Feedback & Retry (Decorator)\n",
    "\n",
    "Wrap any function with a retry **decorator**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c67437f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def retry(retries=3, delay=0.3):\n",
    "    def decorator(fn):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            for i in range(retries):\n",
    "                try:\n",
    "                    return fn(*args, **kwargs)\n",
    "                except Exception as e:\n",
    "                    if i == retries - 1:\n",
    "                        return f\"Failed after {retries} attempts: {e}\"\n",
    "                    time.sleep(delay)\n",
    "            return None\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "@retry(retries=3, delay=0.2)\n",
    "def sometimes_fails():\n",
    "    if random.random() < 0.7:\n",
    "        raise RuntimeError(\"Network hiccup\")\n",
    "    return \"Success ✅\"\n",
    "\n",
    "print(sometimes_fails())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8d07b0",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Switching to Real APIs (Optional)\n",
    "\n",
    "**OpenAI (pseudo-code):**\n",
    "```python\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "resp = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello\"}]\n",
    ")\n",
    "print(resp.choices[0].message[\"content\"])\n",
    "```\n",
    "\n",
    "**Weather via wttr.in:**\n",
    "```python\n",
    "import requests\n",
    "print(requests.get(\"http://wttr.in/Chicago?format=3\", timeout=10).text)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1062695-b6e3-49e6-a0d9-4bc576d2c51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def tool_using_agent(user_input: str) -> str:\n",
    "    text = user_input.lower()\n",
    "    if \"weather\" in text:\n",
    "        # naive city extraction\n",
    "        city = \"Chicago\"\n",
    "        for name in [\"Chicago\", \"New York\", \"London\"]:\n",
    "            if name.lower() in text:\n",
    "                city = name\n",
    "                break\n",
    "        print(\"Agent: I decided to call the weather tool.\")\n",
    "        weather = mock_get_weather(city)\n",
    "        return f\"Weather result → {weather}\"\n",
    "    else:\n",
    "        print(\"Agent: No tool needed; using LLM.\")\n",
    "        return mock_chat([{\"role\": \"user\", \"content\": user_input}])\n",
    "\n",
    "print(tool_using_agent(\"What's the weather in Chicago today?\"))\n",
    "print(tool_using_agent(\"Suggest an evening dinner plan.\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
