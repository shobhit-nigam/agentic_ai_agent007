{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c05c6bc6",
   "metadata": {},
   "source": [
    "# ðŸ§ª Lab 5: Introduction to LangChain\n",
    "\n",
    "## ðŸŽ¯ Objective\n",
    "- Understand **what LangChain is** and why it is used.\n",
    "- Learn how LangChain simplifies building AI-powered applications compared to our manual agentic AI framework from Labs 1â€“4.\n",
    "- Build a simple **LLM Chain** as a first step, following the **Agentic AI lifecycle**.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“– What is LangChain?\n",
    "LangChain is a **framework for building applications with Large Language Models (LLMs)**.\n",
    "\n",
    "Think of it like **Lego for AI apps**:\n",
    "- Instead of writing everything from scratch (like we did in Labs 1â€“4), LangChain gives us **pre-built blocks** (LLMs, tools, memory, chains, agents).\n",
    "- You can snap these blocks together to create powerful AI workflows quickly.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“– Why use LangChain?\n",
    "In Labs 1â€“4, we built everything manually (tools, prompts, memory, decision-making).  \n",
    "That was **educational** but **not scalable**.\n",
    "\n",
    "LangChain helps because:\n",
    "- âœ… Saves time with pre-built blocks\n",
    "- âœ… Consistency in prompt handling\n",
    "- âœ… Extensible (easily add APIs, databases, memory)\n",
    "- âœ… Community support and best practices\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d789d68c",
   "metadata": {},
   "source": [
    "## ðŸ›  Installation\n",
    "\n",
    "Make sure you have Python 3.9+ installed.  \n",
    "Then install the required libraries:\n",
    "\n",
    "```bash\n",
    "pip install langchain openai\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01382fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import required modules\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72991931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define the LLM (the \"brain\")\n",
    "# Replace with your model of choice (gpt-3.5-turbo, gpt-4, etc.)\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8e470f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create a Prompt Template\n",
    "template = \"\"\"You are an AI assistant.\n",
    "Explain the concept of Agentic AI in {num_sentences} simple sentences.\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"num_sentences\"],\n",
    "    template=template\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391740b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Build the Chain\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0579cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Run the Chain\n",
    "result = chain.run(num_sentences=3)\n",
    "print(\"=== Agentic AI Explanation ===\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4773fb6",
   "metadata": {},
   "source": [
    "## ðŸ”„ Reflection (Comparing with Labs 1â€“4)\n",
    "- In Labs 1â€“4, we built prompts, memory, and reasoning **manually** with many files.\n",
    "- In Lab 5 with LangChain:\n",
    "  - **LLM** is wrapped with `ChatOpenAI`.\n",
    "  - **Prompts** are structured with `PromptTemplate`.\n",
    "  - **Execution** is handled by `LLMChain`.\n",
    "\n",
    "ðŸ‘‰ Same **Agentic AI lifecycle**, but much simpler and reusable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2929e4",
   "metadata": {},
   "source": [
    "## ðŸ“Š Visual Mapping (Lab 4 vs Lab 5)\n",
    "Refer to the diagram provided separately (`Lab4_vs_Lab5_Lifecycle.png`)  \n",
    "to see how each manual component is mapped to a LangChain block.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
