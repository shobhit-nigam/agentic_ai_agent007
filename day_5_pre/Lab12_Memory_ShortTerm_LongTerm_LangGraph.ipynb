{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98859156",
   "metadata": {},
   "source": [
    "# Lab 12: Memory Systems — Short‑Term vs Long‑Term + Conversation Summaries (LangGraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff52472",
   "metadata": {},
   "source": [
    "**Goal:** Add a summarizer node (short‑term memory housekeeping) and load a user profile (long‑term memory)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6de17e",
   "metadata": {},
   "source": [
    "### Setup\n",
    "```bash\n",
    "pip install -U langgraph langchain langchain-openai typing_extensions tiktoken\n",
    "export OPENAI_API_KEY=\"your_key\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dfb498",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Dict, Tuple, Optional\n",
    "import re, json, os\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.tools import tool\n",
    "from langchain_core.messages import AnyMessage, HumanMessage, SystemMessage, AIMessage, ToolMessage\n",
    "from typing_extensions import TypedDict, Annotated\n",
    "from operator import add\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.checkpoint.memory import MemorySaver\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9673854",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772929e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tool(\"get_weather\", return_direct=False)\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Return a minimal weather string for the given city using a tiny offline map.\"\"\"\n",
    "    weather_db: Dict[str, str] = {\"paris\":\"sunny, 24°C\",\"chicago\":\"cloudy, 18°C\",\"mumbai\":\"rainy, 30°C\",\"london\":\"overcast, 17°C\",\"tokyo\":\"clear, 26°C\"}\n",
    "    c = city.strip().lower()\n",
    "    return f\"The weather in {city} is {weather_db[c]}.\" if c in weather_db else f\"No weather found for '{city}'. Assume mild (22°C) and clear for demo.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f6176f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tool(\"mini_wiki\", return_direct=False)\n",
    "def mini_wiki(topic: str) -> str:\n",
    "    \"\"\"Return a one-sentence fact for a known city from a tiny offline KB.\"\"\"\n",
    "    kb: Dict[str, str] = {\"paris\":\"Paris is the capital of France, known for the Eiffel Tower and the Louvre.\",\"london\":\"London is the capital of the UK, home to the British Museum and the Thames.\",\"tokyo\":\"Tokyo blends tradition and technology; famous for Shibuya Crossing and Ueno Park.\",\"mumbai\":\"Mumbai is India's financial hub, known for Marine Drive and film industry.\",\"chicago\":\"Chicago sits on Lake Michigan; known for the Riverwalk and deep-dish pizza.\"}\n",
    "    return kb.get(topic.strip().lower(), \"No entry found in mini_wiki.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdf635a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _parse_city_weather(query: str):\n",
    "    import re\n",
    "    q = query.strip()\n",
    "    if \";\" in q or \"city=\" in q.lower():\n",
    "        parts = [p.strip() for p in q.split(\";\")]\n",
    "        city, weather = \"\", \"\"\n",
    "        for p in parts:\n",
    "            if \"=\" in p:\n",
    "                k, v = p.split(\"=\", 1)\n",
    "                k = k.strip().lower(); v = v.strip()\n",
    "                if k == \"city\": city = v\n",
    "                elif k == \"weather\": weather = v\n",
    "        if not city: city = re.split(r\"[;,]\", q)[0].replace(\"city\",\"\").replace(\"=\",\"\").strip()\n",
    "        return city, weather\n",
    "    return q, \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b56d10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tool(\"suggest_city_activities\", return_direct=False)\n",
    "def suggest_city_activities(query: str) -> str:\n",
    "    \"\"\"Recommend ONE indoor and ONE outdoor activity for a city.\"\"\"\n",
    "    catalog = {\"chicago\":{\"indoor\":[\"Art Institute of Chicago\",\"Museum of Science and Industry\",\"Field Museum\"],\"outdoor\":[\"Chicago Riverwalk\",\"Millennium Park\",\"Navy Pier\"]},\"paris\":{\"indoor\":[\"Louvre Museum\",\"Musée d'Orsay\"],\"outdoor\":[\"Seine River Walk\",\"Jardin du Luxembourg\"]},\"london\":{\"indoor\":[\"British Museum\",\"Tate Modern\"],\"outdoor\":[\"Hyde Park\",\"South Bank Walk\"]},\"tokyo\":{\"indoor\":[\"teamLab Planets\",\"Tokyo National Museum\"],\"outdoor\":[\"Ueno Park\",\"Shibuya Crossing Walk\"]},\"mumbai\":{\"indoor\":[\"Chhatrapati Shivaji Maharaj Vastu Sangrahalaya\",\"Phoenix Mall\"],\"outdoor\":[\"Marine Drive\",\"Sanjay Gandhi National Park\"]}}\n",
    "    city, weather = _parse_city_weather(query)\n",
    "    c = city.strip().lower()\n",
    "    if not c: return \"Please provide a city name.\"\n",
    "    data = catalog.get(c)\n",
    "    if not data: return \"General: Indoor - museum/aquarium. Outdoor - central park/riverfront.\"\n",
    "    w = (weather or \"\").lower()\n",
    "    indoor_first = any(k in w for k in [\"rain\",\"storm\"]) or (\"overcast\" in w and \"cold\" in w)\n",
    "    if indoor_first: indoor, outdoor = data[\"indoor\"][0], data[\"outdoor\"][0]\n",
    "    elif any(k in w for k in [\"sunny\",\"clear\"]): outdoor, indoor = data[\"outdoor\"][0], data[\"indoor\"][0]\n",
    "    else: indoor, outdoor = data[\"indoor\"][0], data[\"outdoor\"][0]\n",
    "    return f\"City: {city}. Indoor: {indoor}. Outdoor: {outdoor}. (Weather-aware heuristics.)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7c35c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tool(\"calculator\", return_direct=False)\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"Evaluate a simple math expression (digits + + - * / ( ) . %).\"\"\"\n",
    "    import math, re\n",
    "    if not re.fullmatch(r\"[0-9+\\-*/(). %\\s]+\", expression): return \"Calculator error: invalid characters.\"\n",
    "    try: return str(eval(expression, {\"__builtins__\": {}}, {\"math\": math}))\n",
    "    except Exception as e: return f\"Calculator error: {e}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7716dd",
   "metadata": {},
   "source": [
    "### Build Graph with Planner, Executor, Summarizer (STM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5342836e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing_extensions import TypedDict, Annotated\n",
    "from operator import add\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import AnyMessage, HumanMessage, SystemMessage, AIMessage, ToolMessage\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "TOOLS = [get_weather, mini_wiki, suggest_city_activities, calculator]\n",
    "\n",
    "class MemState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add]\n",
    "    plan: dict | None\n",
    "    exec_result: str | None\n",
    "    summary: str | None\n",
    "    turn_count: int\n",
    "    user_profile: dict | None\n",
    "\n",
    "planner_llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "executor_llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "executor_llm_with_tools = executor_llm.bind_tools(TOOLS)\n",
    "summ_llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "PLANNER_SYS = \"You are PLANNER. JSON only. Use user preferences from SYSTEM messages.\"\n",
    "EXECUTOR_SYS = \"You are EXECUTOR. Execute step with tools, or summarize the latest tool result as EXEC_RESULT: <one line>.\"\n",
    "\n",
    "def _extract_json(text: str):\n",
    "    import re, json\n",
    "    try: return json.loads(text)\n",
    "    except Exception:\n",
    "        m = re.search(r\"\\{.*\\}\\s*$\", text, re.S)\n",
    "        return json.loads(m.group(0)) if m else {}\n",
    "\n",
    "def planner_node(state: MemState) -> MemState:\n",
    "    msgs = state[\"messages\"]\n",
    "    sys_msgs = []\n",
    "    if not msgs or msgs[0].type != \"system\":\n",
    "        sys_msgs.append(SystemMessage(content=PLANNER_SYS))\n",
    "        profile = state.get(\"user_profile\") or {}\n",
    "        if profile:\n",
    "            prefs = profile.get(\"preferences\", {})\n",
    "            sys_msgs.append(SystemMessage(content=f\"User profile: name={profile.get('name','User')}. Preferences={prefs}\"))\n",
    "        if state.get(\"summary\"):\n",
    "            sys_msgs.append(SystemMessage(content=f\"Conversation summary so far:\\n{state['summary']}\"))\n",
    "    response = planner_llm.invoke(sys_msgs + msgs)\n",
    "    turn = int(state.get(\"turn_count\", 0)) + 1\n",
    "    return {\"messages\": [response], \"plan\": _extract_json(response.content), \"turn_count\": turn}\n",
    "\n",
    "def executor_node(state: MemState) -> MemState:\n",
    "    msgs = list(state[\"messages\"])\n",
    "    last = msgs[-1]\n",
    "    if isinstance(last, ToolMessage):\n",
    "        exec_msgs = msgs + [SystemMessage(content=EXECUTOR_SYS), HumanMessage(content=\"Summarize as EXEC_RESULT: ...\")]\n",
    "    else:\n",
    "        step = (state.get(\"plan\") or {}).get(\"next_step\", {})\n",
    "        exec_msgs = msgs + [SystemMessage(content=EXECUTOR_SYS), HumanMessage(content=f\"Step to execute: {json.dumps(step)}\")]\n",
    "    response = executor_llm_with_tools.invoke(exec_msgs)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def summarizer_node(state: MemState) -> MemState:\n",
    "    msgs = state[\"messages\"]\n",
    "    recent = []\n",
    "    for m in msgs[-20:]:\n",
    "        if m.type in (\"human\",\"ai\",\"tool\"):\n",
    "            recent.append(f\"[{m.type}] {getattr(m,'content','')}\")\n",
    "    prompt = [SystemMessage(content=\"Summarize in 5 bullets, keep user prefs and key facts.\"),\n",
    "              HumanMessage(content=\"\\n\".join(recent) if recent else \"No prior content.\")]\n",
    "    summary = summ_llm.invoke(prompt).content.strip()\n",
    "    return {\"messages\": [SystemMessage(content=f\"Conversation summary so far:\\n{summary}\")], \"summary\": summary}\n",
    "\n",
    "graph = StateGraph(MemState)\n",
    "graph.add_node(\"planner\", planner_node)\n",
    "graph.add_node(\"executor\", executor_node)\n",
    "graph.add_node(\"tools\", ToolNode(TOOLS))\n",
    "graph.add_node(\"summarizer\", summarizer_node)\n",
    "\n",
    "def route_from_planner(state: MemState):\n",
    "    if (state.get(\"plan\") or {}).get(\"done\"): return END\n",
    "    return \"summarizer\" if (int(state.get(\"turn_count\",0)) % 3 == 0) else \"executor\"\n",
    "\n",
    "def route_from_summarizer(state: MemState): return \"executor\"\n",
    "def route_from_executor(state: MemState):\n",
    "    last = state[\"messages\"][-1]\n",
    "    tc = getattr(last,\"tool_calls\",None) or (getattr(last,\"additional_kwargs\",{}) or {}).get(\"tool_calls\")\n",
    "    return \"tools\" if tc else \"planner\"\n",
    "\n",
    "graph.set_entry_point(\"planner\")\n",
    "graph.add_conditional_edges(\"planner\", route_from_planner)\n",
    "graph.add_conditional_edges(\"summarizer\", route_from_summarizer)\n",
    "graph.add_conditional_edges(\"executor\", route_from_executor)\n",
    "graph.add_edge(\"tools\", \"executor\")\n",
    "\n",
    "checkpointer = MemorySaver()\n",
    "app = graph.compile(checkpointer=checkpointer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59950c3e",
   "metadata": {},
   "source": [
    "### Demo: LTM (profile) + STM (summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e184236",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_user_profile():\n",
    "    return {\"name\":\"Priya\",\"preferences\":{\"indoor\": True, \"budget\": \"low\", \"likes_museums\": True}}\n",
    "\n",
    "cfg = {\"configurable\": {\"thread_id\": \"lab12-notebook\"}}\n",
    "state_in = {\n",
    "    \"messages\": [HumanMessage(content=\"Plan a short evening in Paris. Keep my preferences in mind. First weather, then one indoor and one outdoor, then finalize.\")]\n",
    "    , \"plan\": None, \"exec_result\": None, \"summary\": None, \"turn_count\": 0, \"user_profile\": load_user_profile()\n",
    "}\n",
    "out = app.invoke(state_in, cfg)\n",
    "out[\"messages\"][-1]\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
